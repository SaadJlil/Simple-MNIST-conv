Using pytorch to train MNIST on a minimal ML architecture. 

NN architecture:

. Convolution layer 1: 1->28
. Convolution layer 2: 28->64
. Linear Layer 1: 9216 ->128
. Linear Layer 2: 128 ->10

Loss function: log_softmax + nll_loss

Batch size: 20

This mini project is not complete. Please don't hesitate to submit a pull request, to make it better.
